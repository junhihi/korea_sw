{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다형성\n",
    "\n",
    "singledispatch로 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import singledispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@singledispatch\n",
    "def xx(t):          # 파라미터가 한개 있을 때 single\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@xx.register(int)\n",
    "def _(t):           # 파라미터가 두개이상 있을 때, multiple\n",
    "    print('int')    # generic 함수\n",
    "    return t\n",
    "\n",
    "@xx.register(str)\n",
    "def _(t):\n",
    "    print('str')\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int\n",
      "str\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1, 's')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx(1.), xx(1), xx('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>smoker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Sat</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Sat</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Sat</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Sat</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Thur</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      day smoker\n",
       "0     Sun     No\n",
       "1     Sun     No\n",
       "2     Sun     No\n",
       "3     Sun     No\n",
       "4     Sun     No\n",
       "..    ...    ...\n",
       "239   Sat     No\n",
       "240   Sat    Yes\n",
       "241   Sat    Yes\n",
       "242   Sat     No\n",
       "243  Thur     No\n",
       "\n",
       "[244 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips[['day', 'smoker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>244.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.785943</td>\n",
       "      <td>2.998279</td>\n",
       "      <td>2.569672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.902412</td>\n",
       "      <td>1.383638</td>\n",
       "      <td>0.951100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.070000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.347500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.795000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.127500</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_bill         tip        size\n",
       "count  244.000000  244.000000  244.000000\n",
       "mean    19.785943    2.998279    2.569672\n",
       "std      8.902412    1.383638    0.951100\n",
       "min      3.070000    1.000000    1.000000\n",
       "25%     13.347500    2.000000    2.000000\n",
       "50%     17.795000    2.900000    2.000000\n",
       "75%     24.127500    3.562500    3.000000\n",
       "max     50.810000   10.000000    6.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sequence dataset의 장점\n",
    "\n",
    "데이터는 순서가 있는 데이터로 만들어주는것이 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.trainers.data_adapters.py_dataset_adapter.PyDataset"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.Sequence # 순서가 있는 dataset\n",
    "                        # 인덱스가 슬라이싱 되어있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@keras_export([\"keras.utils.PyDataset\", \"keras.utils.Sequence\"])\n",
      "class PyDataset:\n",
      "    \"\"\"Base class for defining a parallel dataset using Python code.\n",
      "\n",
      "    Every `PyDataset` must implement the `__getitem__()` and the `__len__()`\n",
      "    methods. If you want to modify your dataset between epochs,\n",
      "    you may additionally implement `on_epoch_end()`,\n",
      "    or `on_epoch_begin` to be called at the start of each epoch.\n",
      "    The `__getitem__()` method should return a complete batch\n",
      "    (not a single sample), and the `__len__` method should return\n",
      "    the number of batches in the dataset (rather than the number of samples).\n",
      "\n",
      "    Args:\n",
      "        workers: Number of workers to use in multithreading or\n",
      "            multiprocessing.\n",
      "        use_multiprocessing: Whether to use Python multiprocessing for\n",
      "            parallelism. Setting this to `True` means that your\n",
      "            dataset will be replicated in multiple forked processes.\n",
      "            This is necessary to gain compute-level (rather than I/O level)\n",
      "            benefits from parallelism. However it can only be set to\n",
      "            `True` if your dataset can be safely pickled.\n",
      "        max_queue_size: Maximum number of batches to keep in the queue\n",
      "            when iterating over the dataset in a multithreaded or\n",
      "            multiprocessed setting.\n",
      "            Reduce this value to reduce the CPU memory consumption of\n",
      "            your dataset. Defaults to 10.\n",
      "\n",
      "    Notes:\n",
      "\n",
      "    - `PyDataset` is a safer way to do multiprocessing.\n",
      "        This structure guarantees that the model will only train\n",
      "        once on each sample per epoch, which is not the case\n",
      "        with Python generators.\n",
      "    - The arguments `workers`, `use_multiprocessing`, and `max_queue_size`\n",
      "        exist to configure how `fit()` uses parallelism to iterate\n",
      "        over the dataset. They are not being used by the `PyDataset` class\n",
      "        directly. When you are manually iterating over a `PyDataset`,\n",
      "        no parallelism is applied.\n",
      "\n",
      "    Example:\n",
      "\n",
      "    ```python\n",
      "    from skimage.io import imread\n",
      "    from skimage.transform import resize\n",
      "    import numpy as np\n",
      "    import math\n",
      "\n",
      "    # Here, `x_set` is list of path to the images\n",
      "    # and `y_set` are the associated classes.\n",
      "\n",
      "    class CIFAR10PyDataset(keras.utils.PyDataset):\n",
      "\n",
      "        def __init__(self, x_set, y_set, batch_size, **kwargs):\n",
      "            super().__init__(**kwargs)\n",
      "            self.x, self.y = x_set, y_set\n",
      "            self.batch_size = batch_size\n",
      "\n",
      "        def __len__(self):\n",
      "            # Return number of batches.\n",
      "            return math.ceil(len(self.x) / self.batch_size)\n",
      "\n",
      "        def __getitem__(self, idx):\n",
      "            # Return x, y for batch idx.\n",
      "            low = idx * self.batch_size\n",
      "            # Cap upper bound at array length; the last batch may be smaller\n",
      "            # if the total number of items is not a multiple of batch size.\n",
      "            high = min(low + self.batch_size, len(self.x))\n",
      "            batch_x = self.x[low:high]\n",
      "            batch_y = self.y[low:high]\n",
      "\n",
      "            return np.array([\n",
      "                resize(imread(file_name), (200, 200))\n",
      "                   for file_name in batch_x]), np.array(batch_y)\n",
      "    ```\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, workers=1, use_multiprocessing=False, max_queue_size=10):\n",
      "        self._workers = workers\n",
      "        self._use_multiprocessing = use_multiprocessing\n",
      "        self._max_queue_size = max_queue_size\n",
      "\n",
      "    def _warn_if_super_not_called(self):\n",
      "        warn = False\n",
      "        if not hasattr(self, \"_workers\"):\n",
      "            self._workers = 1\n",
      "            warn = True\n",
      "        if not hasattr(self, \"_use_multiprocessing\"):\n",
      "            self._use_multiprocessing = False\n",
      "            warn = True\n",
      "        if not hasattr(self, \"_max_queue_size\"):\n",
      "            self._max_queue_size = 10\n",
      "            warn = True\n",
      "        if warn:\n",
      "            warnings.warn(\n",
      "                \"Your `PyDataset` class should call \"\n",
      "                \"`super().__init__(**kwargs)` in its constructor. \"\n",
      "                \"`**kwargs` can include `workers`, \"\n",
      "                \"`use_multiprocessing`, `max_queue_size`. Do not pass \"\n",
      "                \"these arguments to `fit()`, as they will be ignored.\",\n",
      "                stacklevel=2,\n",
      "            )\n",
      "\n",
      "    @property\n",
      "    def workers(self):\n",
      "        self._warn_if_super_not_called()\n",
      "        return self._workers\n",
      "\n",
      "    @workers.setter\n",
      "    def workers(self, value):\n",
      "        self._workers = value\n",
      "\n",
      "    @property\n",
      "    def use_multiprocessing(self):\n",
      "        self._warn_if_super_not_called()\n",
      "        return self._use_multiprocessing\n",
      "\n",
      "    @use_multiprocessing.setter\n",
      "    def use_multiprocessing(self, value):\n",
      "        self._use_multiprocessing = value\n",
      "\n",
      "    @property\n",
      "    def max_queue_size(self):\n",
      "        self._warn_if_super_not_called()\n",
      "        return self._max_queue_size\n",
      "\n",
      "    @max_queue_size.setter\n",
      "    def max_queue_size(self, value):\n",
      "        self._max_queue_size = value\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"Gets batch at position `index`.\n",
      "\n",
      "        Args:\n",
      "            index: position of the batch in the PyDataset.\n",
      "\n",
      "        Returns:\n",
      "            A batch\n",
      "        \"\"\"\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @property\n",
      "    def num_batches(self):\n",
      "        \"\"\"Number of batches in the PyDataset.\n",
      "\n",
      "        Returns:\n",
      "            The number of batches in the PyDataset or `None` to indicate that\n",
      "            the dataset is infinite.\n",
      "        \"\"\"\n",
      "        # For backwards compatibility, support `__len__`.\n",
      "        if hasattr(self, \"__len__\"):\n",
      "            return len(self)\n",
      "        raise NotImplementedError(\n",
      "            \"You need to implement the `num_batches` property:\\n\\n\"\n",
      "            \"@property\\ndef num_batches(self):\\n  return ...\"\n",
      "        )\n",
      "\n",
      "    def on_epoch_begin(self):\n",
      "        \"\"\"Method called at the beginning of every epoch.\"\"\"\n",
      "        pass\n",
      "\n",
      "    def on_epoch_end(self):\n",
      "        \"\"\"Method called at the end of every epoch.\"\"\"\n",
      "        pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 누가 만든 코드를 보고싶을 때 쓰면 된다. (inspect.getsource())\n",
    "print(inspect.getsource(tf.keras.utils.Sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이것을 구현하면 시퀀스 데이터가 된다\n",
    "__getitem__ / __len__ # protocol <- duck typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 상속의 장단점\n",
    "\n",
    "* 장점\n",
    "\n",
    "상속을 통하면 핵심 기능을 처음부터 만들 필요가 없다\n",
    "\n",
    "\n",
    "duck typing보다 추가 기능을 만들 수가 있다\n",
    "\n",
    "\n",
    "* 단점\n",
    "\n",
    "부모가 바뀌면 다시 싹 다 만들어야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_is_protocol']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(Dataset):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Dataset(Generic[_T_co]):\n",
      "    r\"\"\"An abstract class representing a :class:`Dataset`.\n",
      "\n",
      "    All datasets that represent a map from keys to data samples should subclass\n",
      "    it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      "    data sample for a given key. Subclasses could also optionally overwrite\n",
      "    :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      "    :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      "    of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
      "    optionally implement :meth:`__getitems__`, for speedup batched samples\n",
      "    loading. This method accepts list of indices of samples of batch and returns\n",
      "    list of samples.\n",
      "\n",
      "    .. note::\n",
      "      :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
      "      sampler that yields integral indices.  To make it work with a map-style\n",
      "      dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      "    \"\"\"\n",
      "\n",
      "    def __getitem__(self, index) -> _T_co:\n",
      "        raise NotImplementedError(\"Subclasses of Dataset should implement __getitem__.\")\n",
      "\n",
      "    # def __getitems__(self, indices: List) -> List[_T_co]:\n",
      "    # Not implemented to prevent false-positives in fetcher check in\n",
      "    # torch.utils.data._utils.fetch._MapDatasetFetcher\n",
      "\n",
      "    def __add__(self, other: \"Dataset[_T_co]\") -> \"ConcatDataset[_T_co]\":\n",
      "        return ConcatDataset([self, other])\n",
      "\n",
      "    # No `def __len__(self)` default?\n",
      "    # See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\n",
      "    # in pytorch/torch/utils/data/sampler.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(Dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추상화 (abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "객체지향은 재사용성이 너무 좋음\n",
    "\n",
    "파이썬에서 type은 클래스다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a) # 데이터의 type은 metaclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(int) # type의 type은 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(type) # metatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.__class__ # type(a)와 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__new__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__getattribute__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__add__',\n",
       " '__radd__',\n",
       " '__sub__',\n",
       " '__rsub__',\n",
       " '__mul__',\n",
       " '__rmul__',\n",
       " '__mod__',\n",
       " '__rmod__',\n",
       " '__divmod__',\n",
       " '__rdivmod__',\n",
       " '__pow__',\n",
       " '__rpow__',\n",
       " '__neg__',\n",
       " '__pos__',\n",
       " '__abs__',\n",
       " '__bool__',\n",
       " '__invert__',\n",
       " '__lshift__',\n",
       " '__rlshift__',\n",
       " '__rshift__',\n",
       " '__rrshift__',\n",
       " '__and__',\n",
       " '__rand__',\n",
       " '__xor__',\n",
       " '__rxor__',\n",
       " '__or__',\n",
       " '__ror__',\n",
       " '__int__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__rfloordiv__',\n",
       " '__truediv__',\n",
       " '__rtruediv__',\n",
       " '__index__',\n",
       " 'conjugate',\n",
       " 'bit_length',\n",
       " 'bit_count',\n",
       " 'to_bytes',\n",
       " 'from_bytes',\n",
       " 'as_integer_ratio',\n",
       " '__trunc__',\n",
       " '__floor__',\n",
       " '__ceil__',\n",
       " '__round__',\n",
       " '__getnewargs__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " 'real',\n",
       " 'imag',\n",
       " 'numerator',\n",
       " 'denominator',\n",
       " '__doc__',\n",
       " '__str__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__init__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__getstate__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.__dir__() #dir(a)\n",
    "\n",
    "# 차이점 존재\n",
    "\n",
    "# __dir__()은 정의된 순서대로 보여줌\n",
    "# dir(a)는 sorting해서 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "b = iter(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.__next__() #next(b)와 같다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "규모가 크면 클수록 객체로 만들어야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Door:\n",
    "    def __init__(self, number, status):\n",
    "        self.number = number\n",
    "        self.status = status\n",
    "        \n",
    "    def open(self):\n",
    "        self.status = 'open'\n",
    "        \n",
    "    def close(self):\n",
    "        self.status = 'closed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "door1 = Door(1, 'closed') # Door로 인스턴스를 받는다\n",
    "door2 = Door(1, 'closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "door1 == door2 # 둘은 다르다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6287093840, 6299737232)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(door1), id(door2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = A() \n",
    "a2 = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.x = 3 # x가 갑자기 왜 생겼지.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x',\n",
       " '__module__',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__doc__',\n",
       " '__new__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__init__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__getstate__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'A' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43ma2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'A' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "a2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 3}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(a1) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.x=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0x167bc7370', '0x167bc7370')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스는 메모리가 같다\n",
    "hex(id(door1.__class__)), hex(id(door2.__class__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Door:\n",
    "    colour = 'brown'\n",
    "\n",
    "    def __init__(self, number, status):\n",
    "        self.number = number\n",
    "        self.status = status\n",
    "        \n",
    "    def open(self):\n",
    "        self.status = 'open'\n",
    "        \n",
    "    def close(self):\n",
    "        self.status = 'closed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = Door(1, 'open')\n",
    "d2 = Door(1, 'open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Door.__init__() missing 2 required positional arguments: 'number' and 'status'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m d1 = \u001b[43mDoor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Door.__init__() missing 2 required positional arguments: 'number' and 'status'"
     ]
    }
   ],
   "source": [
    "d1 = Door()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Door:\n",
    "    colour = 'brown'\n",
    "\n",
    "    def __init__(self, number, status):\n",
    "        self.number = number\n",
    "        self.status = status\n",
    "\n",
    "    @classmethod\n",
    "    def knock(cls):\n",
    "        print(\"Knock!\")\n",
    "\n",
    "    def open(self):\n",
    "        self.status = 'open'\n",
    "        \n",
    "    def close(self):\n",
    "        self.status = 'closed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# composition이 딥러닝의 핵심이된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상속이 오용이 될 수 있다\n",
    "\n",
    "자식 클래스와 부모 클래스 사이는 역할 수행 관계가 아니어야함\n",
    "\n",
    "상속은 딥러닝에서 기본이다\n",
    "\n",
    "상속 대신 property를 이용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Door:\n",
    "    colour = 'brown'\n",
    "\n",
    "    def __init__(self, number, status):\n",
    "        self.number = number\n",
    "        self.status = status\n",
    "\n",
    "    @classmethod\n",
    "    def knock(cls):\n",
    "        print(\"Knock!\")\n",
    "\n",
    "    @classmethod\n",
    "    def paint(cls, colour):\n",
    "        cls.colour = colour\n",
    "\n",
    "    def open(self):\n",
    "        self.status = 'open'\n",
    "        \n",
    "    def close(self):\n",
    "        self.status = 'closed'\n",
    "\n",
    "class SecurityDoor(Door):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdoor = SecurityDoor(1, 'closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(SecurityDoor.colour is Door.colour) # 파이썬의 상속은 delegation이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상속을 composition처럼 만들 수 있다\n",
    "\n",
    "# composition은 여러개의 일을 한꺼번에 할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    x = 1\n",
    "    def y(self):\n",
    "        print('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B:\n",
    "    def __init__(self):\n",
    "        self.a = A() # 남의 클래스의 인스턴스를 내 인스턴스 변수로 하는 기법\n",
    "                     # 이것이 composition 테크닉\n",
    "                     # 여러개의 일을 한꺼번에 일을 시킬 수 있다\n",
    "                     # 합성함수 방식으로 일을 시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()         # 함수\n",
    "    f1 = Conv2D(32, 3, activation='relu')   # 함수\n",
    "    f2 = Flatten()                          # 함수\n",
    "    f3 = Dense(128, activation='relu')      # 함수\n",
    "    f4 = Dense(10)                          # 함수\n",
    "\n",
    "  def call(self, x):\n",
    "    return f4(f3(f2(f1(x)))) # 한꺼번에 일시킴 -> composition 테크닉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    # forward를 실행시켜 동시에 일을 할 수 있다\n",
    "    # composition 테크닉\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# composition으로 상속 대신 쓸 수 있다\n",
    "# composition이 상속도 될 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결론\n",
    "\n",
    "### 파이썬은 상속의 형태로 추상화를 구현한다\n",
    "\n",
    "추상화에 가까운 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추상화\n",
    "### 1. 상속의 형태로 구현\n",
    "### 2. 메타클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComposedDoor:\n",
    "    def __init__(self, number, status):\n",
    "        self.door = Door(number, status)\n",
    "        \n",
    "    def __getattr__(self, attr):\n",
    "        return getattr(self.door, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ABCMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koreasw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
