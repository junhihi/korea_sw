{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComposedDoor:\n",
    "    def __init__(self, nuber, status):\n",
    "        self.door = Door(number, status)\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return getattr(self.door, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    x = 1\n",
    "    def y (self):\n",
    "        print('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(A):\n",
    "    pass\n",
    "\n",
    "b = B()\n",
    "b.x # 나한테 찾음 -> 없으면 부모에 찾음\n",
    "b.y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "    def __init__(self):\n",
    "        self.a = A() # composition technique\n",
    "    \n",
    "    def __getattr__(self, x): # 예외 처리\n",
    "        print(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕\n"
     ]
    }
   ],
   "source": [
    "c.안녕 # 예외처리돼서 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = input() # input은 type이 str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-3).__abs__() # 절댓값\n",
    "a.__abs__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(-3, \"__abs__\")() # 문자열을 실행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = input() # input에 __abs__을 입력\n",
    "getattr(-1, t)() # 동적으로 메소드나 함수를 변경시킬 수 있다\n",
    "                 # 문자열을 메소드화 시킨것\n",
    "                 # 문자열을 입력받아서 코딩을 할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "exec() takes at least 1 positional argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m a = \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: exec() takes at least 1 positional argument (0 given)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "    def __init__(self):\n",
    "        self.a = A() # composition technique\n",
    "    \n",
    "    def __getattr__(self, x): # 예외 처리\n",
    "        return getattr(self.a, x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.x # self.a.x 실행\n",
    "    # A().x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    }
   ],
   "source": [
    "c.y() # self.a.y() 실행\n",
    "      # -> A().y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'A' object has no attribute 'z'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mz\u001b[49m \u001b[38;5;66;03m# self.a.z\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mC.__getattr__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \u001b[38;5;66;03m# 예외 처리\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'A' object has no attribute 'z'"
     ]
    }
   ],
   "source": [
    "c.z # self.a.z\n",
    "    # A().z\n",
    "    # A 안에 z가 없어서 에러남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# composition을 이용한 inheritance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추상화\n",
    "### 1. 상속의 형태로 구현\n",
    "### 2. 메타클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __len__, __getitem__만 있으면 sequence data로 만들 수 있다\n",
    "# 상황에 따라서 달라진다\n",
    "# 이런것이 전부 함수형 패러다임에서 시작된 기법들이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시퀀스 데이터는 더하면 붙여준다\n",
    "[1,2,3,4] + [5,6,7,8]\n",
    "\n",
    "=> [1,2,3,4,5,6,7,8]\n",
    "\n",
    "# 연산자를 다른 기능으로 바꿔야한다\n",
    "1. 기존의 것을 상속받아서 원하는 기능으로 만들어줘야한다 => 상속\n",
    "2. duck-typing으로 시퀀스 개념만 붙이면 된다\n",
    "3. 추상화 기법을 이용해야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "class ExpandingSequence(Sequence):\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self._cache = []\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        while len(self._cache) <= index:\n",
    "            self._cache.append(next(self.it))\n",
    "            return self._cache[index]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self._cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __getitem__(self, x): # getitem의 기능을 바꿨다\n",
    "        print('x')            # 연산자 오버로딩(operator overloading)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n"
     ]
    }
   ],
   "source": [
    "a[0] # 인덱싱할때의 기능을 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B:\n",
    "    def __add__(self, x):\n",
    "        print('not add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not add\n"
     ]
    }
   ],
   "source": [
    "b + 3 # 연산자 오버로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence 데이터에서 가장 중요한 기능\n",
    "## 만약 사용자가 구현을 안했을 경우\n",
    "## 내가 주의를 주자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C(Sequence):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class C with abstract methods __getitem__, __len__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m c = \u001b[43mC\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Can't instantiate abstract class C with abstract methods __getitem__, __len__"
     ]
    }
   ],
   "source": [
    "c = C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod, ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(ABC):\n",
    "    @abstractmethod\n",
    "    def t(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class E(D):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class E with abstract method t",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m e = \u001b[43mE\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Can't instantiate abstract class E with abstract method t"
     ]
    }
   ],
   "source": [
    "e = E() # abstractmethod를 만들지 않았다고 경고를 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F:\n",
    "    def s(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T(F):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = T()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[108]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43ms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mF.s\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34ms\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "t.s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@keras_export([\"keras.utils.PyDataset\", \"keras.utils.Sequence\"])\n",
      "class PyDataset:\n",
      "    \"\"\"Base class for defining a parallel dataset using Python code.\n",
      "\n",
      "    Every `PyDataset` must implement the `__getitem__()` and the `__len__()`\n",
      "    methods. If you want to modify your dataset between epochs,\n",
      "    you may additionally implement `on_epoch_end()`,\n",
      "    or `on_epoch_begin` to be called at the start of each epoch.\n",
      "    The `__getitem__()` method should return a complete batch\n",
      "    (not a single sample), and the `__len__` method should return\n",
      "    the number of batches in the dataset (rather than the number of samples).\n",
      "\n",
      "    Args:\n",
      "        workers: Number of workers to use in multithreading or\n",
      "            multiprocessing.\n",
      "        use_multiprocessing: Whether to use Python multiprocessing for\n",
      "            parallelism. Setting this to `True` means that your\n",
      "            dataset will be replicated in multiple forked processes.\n",
      "            This is necessary to gain compute-level (rather than I/O level)\n",
      "            benefits from parallelism. However it can only be set to\n",
      "            `True` if your dataset can be safely pickled.\n",
      "        max_queue_size: Maximum number of batches to keep in the queue\n",
      "            when iterating over the dataset in a multithreaded or\n",
      "            multiprocessed setting.\n",
      "            Reduce this value to reduce the CPU memory consumption of\n",
      "            your dataset. Defaults to 10.\n",
      "\n",
      "    Notes:\n",
      "\n",
      "    - `PyDataset` is a safer way to do multiprocessing.\n",
      "        This structure guarantees that the model will only train\n",
      "        once on each sample per epoch, which is not the case\n",
      "        with Python generators.\n",
      "    - The arguments `workers`, `use_multiprocessing`, and `max_queue_size`\n",
      "        exist to configure how `fit()` uses parallelism to iterate\n",
      "        over the dataset. They are not being used by the `PyDataset` class\n",
      "        directly. When you are manually iterating over a `PyDataset`,\n",
      "        no parallelism is applied.\n",
      "\n",
      "    Example:\n",
      "\n",
      "    ```python\n",
      "    from skimage.io import imread\n",
      "    from skimage.transform import resize\n",
      "    import numpy as np\n",
      "    import math\n",
      "\n",
      "    # Here, `x_set` is list of path to the images\n",
      "    # and `y_set` are the associated classes.\n",
      "\n",
      "    class CIFAR10PyDataset(keras.utils.PyDataset):\n",
      "\n",
      "        def __init__(self, x_set, y_set, batch_size, **kwargs):\n",
      "            super().__init__(**kwargs)\n",
      "            self.x, self.y = x_set, y_set\n",
      "            self.batch_size = batch_size\n",
      "\n",
      "        def __len__(self):\n",
      "            # Return number of batches.\n",
      "            return math.ceil(len(self.x) / self.batch_size)\n",
      "\n",
      "        def __getitem__(self, idx):\n",
      "            # Return x, y for batch idx.\n",
      "            low = idx * self.batch_size\n",
      "            # Cap upper bound at array length; the last batch may be smaller\n",
      "            # if the total number of items is not a multiple of batch size.\n",
      "            high = min(low + self.batch_size, len(self.x))\n",
      "            batch_x = self.x[low:high]\n",
      "            batch_y = self.y[low:high]\n",
      "\n",
      "            return np.array([\n",
      "                resize(imread(file_name), (200, 200))\n",
      "                   for file_name in batch_x]), np.array(batch_y)\n",
      "    ```\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, workers=1, use_multiprocessing=False, max_queue_size=10):\n",
      "        self._workers = workers\n",
      "        self._use_multiprocessing = use_multiprocessing\n",
      "        self._max_queue_size = max_queue_size\n",
      "\n",
      "    def _warn_if_super_not_called(self):\n",
      "        warn = False\n",
      "        if not hasattr(self, \"_workers\"):\n",
      "            self._workers = 1\n",
      "            warn = True\n",
      "        if not hasattr(self, \"_use_multiprocessing\"):\n",
      "            self._use_multiprocessing = False\n",
      "            warn = True\n",
      "        if not hasattr(self, \"_max_queue_size\"):\n",
      "            self._max_queue_size = 10\n",
      "            warn = True\n",
      "        if warn:\n",
      "            warnings.warn(\n",
      "                \"Your `PyDataset` class should call \"\n",
      "                \"`super().__init__(**kwargs)` in its constructor. \"\n",
      "                \"`**kwargs` can include `workers`, \"\n",
      "                \"`use_multiprocessing`, `max_queue_size`. Do not pass \"\n",
      "                \"these arguments to `fit()`, as they will be ignored.\",\n",
      "                stacklevel=2,\n",
      "            )\n",
      "\n",
      "    @property\n",
      "    def workers(self):\n",
      "        self._warn_if_super_not_called()\n",
      "        return self._workers\n",
      "\n",
      "    @workers.setter\n",
      "    def workers(self, value):\n",
      "        self._workers = value\n",
      "\n",
      "    @property\n",
      "    def use_multiprocessing(self):\n",
      "        self._warn_if_super_not_called()\n",
      "        return self._use_multiprocessing\n",
      "\n",
      "    @use_multiprocessing.setter\n",
      "    def use_multiprocessing(self, value):\n",
      "        self._use_multiprocessing = value\n",
      "\n",
      "    @property\n",
      "    def max_queue_size(self):\n",
      "        self._warn_if_super_not_called()\n",
      "        return self._max_queue_size\n",
      "\n",
      "    @max_queue_size.setter\n",
      "    def max_queue_size(self, value):\n",
      "        self._max_queue_size = value\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        \"\"\"Gets batch at position `index`.\n",
      "\n",
      "        Args:\n",
      "            index: position of the batch in the PyDataset.\n",
      "\n",
      "        Returns:\n",
      "            A batch\n",
      "        \"\"\"\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @property\n",
      "    def num_batches(self):\n",
      "        \"\"\"Number of batches in the PyDataset.\n",
      "\n",
      "        Returns:\n",
      "            The number of batches in the PyDataset or `None` to indicate that\n",
      "            the dataset is infinite.\n",
      "        \"\"\"\n",
      "        # For backwards compatibility, support `__len__`.\n",
      "        if hasattr(self, \"__len__\"):\n",
      "            return len(self)\n",
      "        raise NotImplementedError(\n",
      "            \"You need to implement the `num_batches` property:\\n\\n\"\n",
      "            \"@property\\ndef num_batches(self):\\n  return ...\"\n",
      "        )\n",
      "\n",
      "    def on_epoch_begin(self):\n",
      "        \"\"\"Method called at the beginning of every epoch.\"\"\"\n",
      "        pass\n",
      "\n",
      "    def on_epoch_end(self):\n",
      "        \"\"\"Method called at the end of every epoch.\"\"\"\n",
      "        pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(tf.keras.utils.Sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Dataset(Generic[_T_co]):\n",
      "    r\"\"\"An abstract class representing a :class:`Dataset`.\n",
      "\n",
      "    All datasets that represent a map from keys to data samples should subclass\n",
      "    it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      "    data sample for a given key. Subclasses could also optionally overwrite\n",
      "    :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      "    :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      "    of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
      "    optionally implement :meth:`__getitems__`, for speedup batched samples\n",
      "    loading. This method accepts list of indices of samples of batch and returns\n",
      "    list of samples.\n",
      "\n",
      "    .. note::\n",
      "      :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
      "      sampler that yields integral indices.  To make it work with a map-style\n",
      "      dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      "    \"\"\"\n",
      "\n",
      "    def __getitem__(self, index) -> _T_co:\n",
      "        raise NotImplementedError(\"Subclasses of Dataset should implement __getitem__.\")\n",
      "\n",
      "    # def __getitems__(self, indices: List) -> List[_T_co]:\n",
      "    # Not implemented to prevent false-positives in fetcher check in\n",
      "    # torch.utils.data._utils.fetch._MapDatasetFetcher\n",
      "\n",
      "    def __add__(self, other: \"Dataset[_T_co]\") -> \"ConcatDataset[_T_co]\":\n",
      "        return ConcatDataset([self, other])\n",
      "\n",
      "    # No `def __len__(self)` default?\n",
      "    # See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\n",
      "    # in pytorch/torch/utils/data/sampler.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(Dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas가 orm 역할을 대신한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두가지 기능 __getitem__ / __len__\n",
    "\n",
    "1. 상속없이 duck typing\n",
    "2. 상속\n",
    "3. 추상화\n",
    "\n",
    "이 세가지를 알면 실수를 줄일 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections.abc import Sequence\n",
    "class ExpandingSequence(Sequence):\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self._cache = []\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        while len(self._cache) <= index:\n",
    "            self._cache.append(next(self.it))\n",
    "            return self._cache[index]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self._cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOF(higher order function)\n",
    "# 함수의 인자로 함수를 집어넣는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map이 제일 많이 쓰인다\n",
    "# pytorch, tensorflow에서는 map을 lambda로 쓰인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicate = 참 또는 거짓의 값으로 가진것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips =sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>29.03</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>27.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>22.67</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>17.82</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>18.78</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip     sex smoker   day    time  size\n",
       "0         16.99  1.01  Female     No   Sun  Dinner     2\n",
       "1         10.34  1.66    Male     No   Sun  Dinner     3\n",
       "2         21.01  3.50    Male     No   Sun  Dinner     3\n",
       "3         23.68  3.31    Male     No   Sun  Dinner     2\n",
       "4         24.59  3.61  Female     No   Sun  Dinner     4\n",
       "..          ...   ...     ...    ...   ...     ...   ...\n",
       "239       29.03  5.92    Male     No   Sat  Dinner     3\n",
       "240       27.18  2.00  Female    Yes   Sat  Dinner     2\n",
       "241       22.67  2.00    Male    Yes   Sat  Dinner     2\n",
       "242       17.82  1.75    Male     No   Sat  Dinner     2\n",
       "243       18.78  3.00  Female     No  Thur  Dinner     2\n",
       "\n",
       "[244 rows x 7 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1467.53\n",
       "1      2411.98\n",
       "2      5085.50\n",
       "3      4809.43\n",
       "4      5245.33\n",
       "        ...   \n",
       "239    8601.76\n",
       "240    2906.00\n",
       "241    2906.00\n",
       "242    2542.75\n",
       "243    4359.00\n",
       "Name: tip, Length: 244, dtype: float64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.tip.map(lambda x:1453*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda x,y:x+y, [1,2,3,4,5]) # [3,3,4,5] -> [6,4,5] -> [10,5] -> [15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x,y:x+y, [1,2,3],[1,3])) # range가 일치하지 않으면 일치하는 부분만 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch의 map -> Lambda()\n",
    "# tensorflow의 map -> .map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence\n",
    "\n",
    "### [x,y,z]\n",
    "\n",
    "### x->y->z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.abc.Sequence"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compose(*funcs):\n",
    "    \"\"\"Return a new function s.t.\n",
    "    compose(f,g,...)(x) == f(g(...(x)))\"\"\" \n",
    "    def inner(data, funcs=funcs): \n",
    "        result = data \n",
    "        for f in reversed(funcs): \n",
    "            result = f(result) \n",
    "            return result \n",
    "        return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closure에서 함수를 감싸고 기능을 추가한게 decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬은 multi paradime\n",
    "# 데코레이터와 상속의 막강함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 것만 뽑아내는 것 -> Aspect\n",
    "# Aspect programming은 다중상속을 중요시한다\n",
    "# mixins는 중복되지 않게 구성시키는 것\n",
    "\n",
    "# 데코레이터\n",
    "# 공통된 기능을 가진 객체 두개에서 해당 기능만 따로 만든것을 데코레이터라고 한다\n",
    "# 공통된 기능을 효율적으로 사용하기 위하여 뽑아놓은것\n",
    "# 기능을 추가하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(a):\n",
    "    return a\n",
    "\n",
    "# 추가하고 싶은 기능이 있으면 해당 기능만 함수로 만들어서\n",
    "# 추가하고 싶은 함수에다가만 기능을 넣을 수 있는 장점이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s(f):\n",
    "    def ss(x):\n",
    "        print(f.__name__)\n",
    "        return f(x)\n",
    "        print(x)\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "@s              # ss의 인자와 x의 리턴값이 같아야한다\n",
    "def x(a):\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n"
     ]
    }
   ],
   "source": [
    "a = x(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function s.<locals>.ss at 0x312675ee0>\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    @classmethod        # 클래스 메소드가 되었다\n",
    "    def s(cls):\n",
    "        print('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n"
     ]
    }
   ],
   "source": [
    "x(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상속받으면 그 애가 만든거 가져올 수 있다\n",
    "데코레이터는 함수를 만드면 그 기능을 더할 수 있다\n",
    "함수의 기능을 확장시켜주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(fun):\n",
    "    fun('aaaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaa\n"
     ]
    }
   ],
   "source": [
    "x(print) # python은 함수를 first-class function으로 만들었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [print, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n"
     ]
    }
   ],
   "source": [
    "a[0]('aaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(m):           # 클로저 구조\n",
    "    def y(n):\n",
    "        return m+n\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x(2)(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init__ 는 클로저 구조\n",
    "# 클로저에서 첫번째 인자가 함수일 경우:\n",
    "# 데코레이터을 쓸 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xx(fun):        # function closure -> 데코레이터 구조\n",
    "    def yy():\n",
    "        print('aaa')\n",
    "        fun()\n",
    "        print('bbb')\n",
    "    return yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "@xx           # t함수를 xx에 집어넣는다\n",
    "def t():\n",
    "    print('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n",
      "t\n",
      "bbb\n"
     ]
    }
   ],
   "source": [
    "a = t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수형 패러다임에서 함수의 기능을 추가하는 함수를 만들 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "addd = partial(add, 3) # 함수를 부분적으로 바꿀 수 있는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addd(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n",
      "aaa\n",
      "t\n",
      "bbb\n",
      "bbb\n"
     ]
    }
   ],
   "source": [
    "xx(t)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n",
      "ttt\n",
      "bbb\n"
     ]
    }
   ],
   "source": [
    "xx(lambda : print('ttt'))()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    @classmethod    # t를 classmethod에 넣음\n",
    "    def t(cls):     # classmethod(t)()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝에선 함수형 패러다임이 주된 기술이기 때문에 많이 쓰인다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koreasw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
